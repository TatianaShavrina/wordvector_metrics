{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что проверяем:\n",
    "\n",
    "слова из списка сводеша сохраняют ранги своих соседей независимо от модели\n",
    "\n",
    "слова из списка сводеша демонстрируют большую устойчивость к набору соседей, чем случайные слова\n",
    "\n",
    "слова из списка сводеша сохраняют расстояния к частотным словам языка независимо от модели.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# отсечение по рангу\n",
    "5000 слов самых част\n",
    "снизу - \n",
    "отфильтровать по частотности\n",
    "\n",
    "посмотреть частоты списка Сводеша\n",
    "женя глазунов - спросить про метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "'''\n",
    "This module is formatting  user config with facts and entities,\n",
    "creating entity index and producing all variants for entity-match\n",
    "'''\n",
    "\n",
    "import zipfile\n",
    "import gensim\n",
    "\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from operator import itemgetter\n",
    "from scipy import stats\n",
    "import random\n",
    "from functools import lru_cache\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_model(m):\n",
    "    try:\n",
    "        if m.endswith('.vec'):\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False)\n",
    "        elif m.endswith('.bin'):\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=True)\n",
    "\n",
    "        else:\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False, unicode_errors='replace')\n",
    "    except:\n",
    "        model = gensim.models.KeyedVectors.load_word2vec_format(m, binary=False, unicode_errors='replace')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>% intersection</th>\n",
       "      <th>svodesh/random</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>one_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>two_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.064257</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>three_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>four_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.079167</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>five_NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  % intersection svodesh/random       word\n",
       "0           0        0.014652        svodesh    one_NUM\n",
       "1           1        0.039216        svodesh    two_NUM\n",
       "2           2        0.064257        svodesh  three_NUM\n",
       "3           3        0.075000        svodesh   four_NUM\n",
       "4           4        0.079167        svodesh   five_NUM"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/media/mi_air/0F0B7DDE62EEA81E/vector/closest_word_intersection_eng.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequent\n",
    "fr  = df[df['svodesh/random']=='freq']\n",
    "#svodesh\n",
    "sv = df[df['svodesh/random']=='svodesh']\n",
    "#random\n",
    "rn = df[df['svodesh/random']=='random']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# эксперимент 1 - получаем 10 ближайших соседей по каждой модели для каждого слова\n",
    "\n",
    "по аранеа\n",
    "по новостям\n",
    "по нкря\n",
    "по вики\n",
    "\n",
    "затем для каждого слова считаем % пересечения соседей по моделям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dic_svodesh = { 'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_random = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_freq = {'wiki':{},'gigaword':{}, 'bnc':{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#aranea\n",
    "WDIR = r'/media/mi_air/0F0B7DDE62EEA81E/vector/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bnc\n",
    "with zipfile.ZipFile(WDIR + \"bnc_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['bnc']:\n",
    "        dic_freq['bnc'][w] = model.most_similar(w,topn=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['bnc']:\n",
    "        dic_svodesh['bnc'][w] = model.most_similar(w,topn=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['bnc']:\n",
    "        dic_random['bnc'][w] = model.most_similar(w,topn=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "#gigaword\n",
    "with zipfile.ZipFile(WDIR + \"gigaword_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['gigaword']:\n",
    "        try:\n",
    "            dic_freq['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['gigaword'][w] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['gigaword']:\n",
    "        try:\n",
    "            dic_svodesh['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['gigaword'][w] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['gigaword']:\n",
    "        try:\n",
    "            dic_random['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            print(w)\n",
    "            dic_random['gigaword'][w] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wiki\n",
    "with zipfile.ZipFile(WDIR + \"wiki_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['wiki']:\n",
    "        try:\n",
    "            dic_freq['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['wiki'][w] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['wiki']:\n",
    "        try:\n",
    "            dic_svodesh['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['wiki'][w] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['wiki']:\n",
    "        try:\n",
    "            dic_random['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            print(w)\n",
    "            dic_random['wiki'][w] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_set(list1, list2, list3):\n",
    "    set1, set2, set3 = set(list1), set(list2), set(list3)\n",
    "    d = set.intersection(set1, set2, set3)\n",
    "    u = set(list(set1)+list(set2)+list(set3))\n",
    "    return len(d)/len(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_words(dic):\n",
    "    return [i[0] for i in dic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% intersection</th>\n",
       "      <th>svodesh/random</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>one_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>two_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>three_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>four_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>five_NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % intersection svodesh/random       word\n",
       "0        0.176471        svodesh    one_NUM\n",
       "1        0.538462        svodesh    two_NUM\n",
       "2        0.538462        svodesh  three_NUM\n",
       "3        0.538462        svodesh   four_NUM\n",
       "4        0.666667        svodesh   five_NUM"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_list = []\n",
    "for word in list(sv['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'svodesh'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_svodesh['wiki'][word]),get_words(dic_svodesh['bnc'][word]),get_words(dic_svodesh['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(rn['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'random'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_random['wiki'][word]),get_words(dic_random['bnc'][word]),get_words(dic_random['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(fr['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'freq'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_freq['wiki'][word]),get_words(dic_freq['bnc'][word]),get_words(dic_freq['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "df10 = pd.DataFrame(rows_list) \n",
    "df10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "freq       160\n",
       "svodesh    160\n",
       "random     160\n",
       "Name: svodesh/random, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df10['svodesh/random'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequent\n",
    "fr  = df10[df10['svodesh/random']=='freq']\n",
    "#svodesh\n",
    "sv = df10[df10['svodesh/random']=='svodesh']\n",
    "#random\n",
    "rn = df10[df10['svodesh/random']=='random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#манн-уитни\n",
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18620.5, pvalue=0.999999999999876)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Получается, что нулевая гипотеза о том, что степень признака в выборках неравна (в первой меньше) неверна\n",
    "#принимается альтернативная гипотеза, что в случайной выборке слов степень признака меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=16545.5, pvalue=0.9999977045748956)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(fr['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=15446.0, pvalue=0.9996034380330993)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(fr['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# получается, что слова из списка сводеша более устойчивы к различным моделям, чем просто частотные слова\n",
    "# а частотные слова более устойчивы, чем случайные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df10.to_csv(path_or_buf='/media/mi_air/0F0B7DDE62EEA81E/vector/closest_word_intersection_10_eng.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 20 ближайших"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% intersection</th>\n",
       "      <th>svodesh/random</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060000</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>one_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.162791</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>two_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>three_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>four_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>five_NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % intersection svodesh/random       word\n",
       "0        0.060000        svodesh    one_NUM\n",
       "1        0.162791        svodesh    two_NUM\n",
       "2        0.225000        svodesh  three_NUM\n",
       "3        0.225000        svodesh   four_NUM\n",
       "4        0.277778        svodesh   five_NUM"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 20\n",
    "dic_svodesh = { 'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_random = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_freq = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "\n",
    "#bnc\n",
    "with zipfile.ZipFile(WDIR + \"bnc_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['bnc']:\n",
    "        dic_freq['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['bnc']:\n",
    "        dic_svodesh['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['bnc']:\n",
    "        dic_random['bnc'][w] = model.most_similar(w,topn=num)\n",
    "#gigaword\n",
    "with zipfile.ZipFile(WDIR + \"gigaword_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['gigaword']:\n",
    "        try:\n",
    "            dic_freq['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['gigaword'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['gigaword']:\n",
    "        try:\n",
    "            dic_svodesh['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['gigaword'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['gigaword']:\n",
    "        try:\n",
    "            dic_random['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            print(w)\n",
    "            dic_random['gigaword'][w] = []        \n",
    "#wiki\n",
    "with zipfile.ZipFile(WDIR + \"wiki_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['wiki']:\n",
    "        try:\n",
    "            dic_freq['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['wiki'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['wiki']:\n",
    "        try:\n",
    "            dic_svodesh['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['wiki'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['wiki']:\n",
    "        try:\n",
    "            dic_random['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_random['wiki'][w] = []       \n",
    "        \n",
    "rows_list = []\n",
    "for word in list(sv['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'svodesh'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_svodesh['wiki'][word]),get_words(dic_svodesh['bnc'][word]),get_words(dic_svodesh['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(rn['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'random'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_random['wiki'][word]),get_words(dic_random['bnc'][word]),get_words(dic_random['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(fr['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'freq'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_freq['wiki'][word]),get_words(dic_freq['bnc'][word]),get_words(dic_freq['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "df20 = pd.DataFrame(rows_list) \n",
    "df20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequent\n",
    "fr  = df20[df20['svodesh/random']=='freq']\n",
    "#svodesh\n",
    "sv = df20[df20['svodesh/random']=='svodesh']\n",
    "#random\n",
    "rn = df20[df20['svodesh/random']=='random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=19159.0, pvalue=0.999999999999999)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=13096.0, pvalue=0.6406762402587186)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(fr['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18712.5, pvalue=0.9999999999999486)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(fr['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df20.to_csv(path_or_buf='/media/mi_air/0F0B7DDE62EEA81E/vector/closest_word_intersection_20_eng.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 ближайших"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% intersection</th>\n",
       "      <th>svodesh/random</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030303</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>one_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.082645</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>two_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.082645</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>three_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.107143</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>four_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.140187</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>five_NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % intersection svodesh/random       word\n",
       "0        0.030303        svodesh    one_NUM\n",
       "1        0.082645        svodesh    two_NUM\n",
       "2        0.082645        svodesh  three_NUM\n",
       "3        0.107143        svodesh   four_NUM\n",
       "4        0.140187        svodesh   five_NUM"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 50\n",
    "dic_svodesh = { 'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_random = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_freq = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "\n",
    "#bnc\n",
    "with zipfile.ZipFile(WDIR + \"bnc_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['bnc']:\n",
    "        dic_freq['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['bnc']:\n",
    "        dic_svodesh['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['bnc']:\n",
    "        dic_random['bnc'][w] = model.most_similar(w,topn=num)\n",
    "#gigaword\n",
    "with zipfile.ZipFile(WDIR + \"gigaword_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['gigaword']:\n",
    "        try:\n",
    "            dic_freq['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['gigaword'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['gigaword']:\n",
    "        try:\n",
    "            dic_svodesh['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['gigaword'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['gigaword']:\n",
    "        try:\n",
    "            dic_random['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            print(w)\n",
    "            dic_random['gigaword'][w] = []        \n",
    "#wiki\n",
    "with zipfile.ZipFile(WDIR + \"wiki_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['wiki']:\n",
    "        try:\n",
    "            dic_freq['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['wiki'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['wiki']:\n",
    "        try:\n",
    "            dic_svodesh['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['wiki'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['wiki']:\n",
    "        try:\n",
    "            dic_random['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_random['wiki'][w] = []       \n",
    "        \n",
    "rows_list = []\n",
    "for word in list(sv['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'svodesh'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_svodesh['wiki'][word]),get_words(dic_svodesh['bnc'][word]),get_words(dic_svodesh['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(rn['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'random'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_random['wiki'][word]),get_words(dic_random['bnc'][word]),get_words(dic_random['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(fr['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'freq'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_freq['wiki'][word]),get_words(dic_freq['bnc'][word]),get_words(dic_freq['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "df50 = pd.DataFrame(rows_list) \n",
    "df50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequent\n",
    "fr  = df50[df50['svodesh/random']=='freq']\n",
    "#svodesh\n",
    "sv = df50[df50['svodesh/random']=='svodesh']\n",
    "#random\n",
    "rn = df50[df50['svodesh/random']=='random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=19007.5, pvalue=0.9999999999999858)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=13432.0, pvalue=0.7778477155381815)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(fr['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18592.5, pvalue=0.9999999999993766)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(fr['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df50.to_csv(path_or_buf='/media/mi_air/0F0B7DDE62EEA81E/vector/closest_word_intersection_50_eng.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 ближайших"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% intersection</th>\n",
       "      <th>svodesh/random</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014652</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>one_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.039216</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>two_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064257</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>three_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>four_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.079167</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>five_NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % intersection svodesh/random       word\n",
       "0        0.014652        svodesh    one_NUM\n",
       "1        0.039216        svodesh    two_NUM\n",
       "2        0.064257        svodesh  three_NUM\n",
       "3        0.075000        svodesh   four_NUM\n",
       "4        0.079167        svodesh   five_NUM"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 100\n",
    "dic_svodesh = { 'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_random = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_freq = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "\n",
    "#bnc\n",
    "with zipfile.ZipFile(WDIR + \"bnc_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['bnc']:\n",
    "        dic_freq['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['bnc']:\n",
    "        dic_svodesh['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['bnc']:\n",
    "        dic_random['bnc'][w] = model.most_similar(w,topn=num)\n",
    "#gigaword\n",
    "with zipfile.ZipFile(WDIR + \"gigaword_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['gigaword']:\n",
    "        try:\n",
    "            dic_freq['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['gigaword'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['gigaword']:\n",
    "        try:\n",
    "            dic_svodesh['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['gigaword'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['gigaword']:\n",
    "        try:\n",
    "            dic_random['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            print(w)\n",
    "            dic_random['gigaword'][w] = []        \n",
    "#wiki\n",
    "with zipfile.ZipFile(WDIR + \"wiki_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['wiki']:\n",
    "        try:\n",
    "            dic_freq['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['wiki'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['wiki']:\n",
    "        try:\n",
    "            dic_svodesh['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['wiki'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['wiki']:\n",
    "        try:\n",
    "            dic_random['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_random['wiki'][w] = []       \n",
    "        \n",
    "rows_list = []\n",
    "for word in list(sv['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'svodesh'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_svodesh['wiki'][word]),get_words(dic_svodesh['bnc'][word]),get_words(dic_svodesh['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(rn['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'random'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_random['wiki'][word]),get_words(dic_random['bnc'][word]),get_words(dic_random['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(fr['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'freq'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_freq['wiki'][word]),get_words(dic_freq['bnc'][word]),get_words(dic_freq['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "df100 = pd.DataFrame(rows_list) \n",
    "df100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequent\n",
    "fr  = df100[df100['svodesh/random']=='freq']\n",
    "#svodesh\n",
    "sv = df100[df100['svodesh/random']=='svodesh']\n",
    "#random\n",
    "rn = df100[df100['svodesh/random']=='random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18873.0, pvalue=0.999999999999925)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=14105.5, pvalue=0.9427752492732502)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(fr['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18256.0, pvalue=0.9999999999837672)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(fr['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df100.to_csv(path_or_buf='/media/mi_air/0F0B7DDE62EEA81E/vector/closest_word_intersection_100_eng.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 200 ближайших"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% intersection</th>\n",
       "      <th>svodesh/random</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009242</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>one_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022642</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>two_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.038911</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>three_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048290</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>four_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068522</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>five_NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % intersection svodesh/random       word\n",
       "0        0.009242        svodesh    one_NUM\n",
       "1        0.022642        svodesh    two_NUM\n",
       "2        0.038911        svodesh  three_NUM\n",
       "3        0.048290        svodesh   four_NUM\n",
       "4        0.068522        svodesh   five_NUM"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 200\n",
    "dic_svodesh = { 'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_random = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_freq = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "\n",
    "#bnc\n",
    "with zipfile.ZipFile(WDIR + \"bnc_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['bnc']:\n",
    "        dic_freq['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['bnc']:\n",
    "        dic_svodesh['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['bnc']:\n",
    "        dic_random['bnc'][w] = model.most_similar(w,topn=num)\n",
    "#gigaword\n",
    "with zipfile.ZipFile(WDIR + \"gigaword_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['gigaword']:\n",
    "        try:\n",
    "            dic_freq['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['gigaword'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['gigaword']:\n",
    "        try:\n",
    "            dic_svodesh['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['gigaword'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['gigaword']:\n",
    "        try:\n",
    "            dic_random['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            print(w)\n",
    "            dic_random['gigaword'][w] = []        \n",
    "#wiki\n",
    "with zipfile.ZipFile(WDIR + \"wiki_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['wiki']:\n",
    "        try:\n",
    "            dic_freq['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['wiki'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['wiki']:\n",
    "        try:\n",
    "            dic_svodesh['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['wiki'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['wiki']:\n",
    "        try:\n",
    "            dic_random['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_random['wiki'][w] = []       \n",
    "        \n",
    "rows_list = []\n",
    "for word in list(sv['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'svodesh'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_svodesh['wiki'][word]),get_words(dic_svodesh['bnc'][word]),get_words(dic_svodesh['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(rn['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'random'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_random['wiki'][word]),get_words(dic_random['bnc'][word]),get_words(dic_random['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(fr['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'freq'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_freq['wiki'][word]),get_words(dic_freq['bnc'][word]),get_words(dic_freq['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "df200 = pd.DataFrame(rows_list) \n",
    "df200.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequent\n",
    "fr  = df200[df200['svodesh/random']=='freq']\n",
    "#svodesh\n",
    "sv = df200[df200['svodesh/random']=='svodesh']\n",
    "#random\n",
    "rn = df200[df200['svodesh/random']=='random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18655.5, pvalue=0.9999999999993926)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=14544.5, pvalue=0.9825194326149029)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(fr['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18032.0, pvalue=0.9999999998865872)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(fr['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df200.to_csv(path_or_buf='/media/mi_air/0F0B7DDE62EEA81E/vector/closest_word_intersection_200_eng.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 300 ближайших"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mi_air/.local/lib/python3.5/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>% intersection</th>\n",
       "      <th>svodesh/random</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.008505</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>one_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018428</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>two_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.028061</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>three_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035526</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>four_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062155</td>\n",
       "      <td>svodesh</td>\n",
       "      <td>five_NUM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   % intersection svodesh/random       word\n",
       "0        0.008505        svodesh    one_NUM\n",
       "1        0.018428        svodesh    two_NUM\n",
       "2        0.028061        svodesh  three_NUM\n",
       "3        0.035526        svodesh   four_NUM\n",
       "4        0.062155        svodesh   five_NUM"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = 300\n",
    "dic_svodesh = { 'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_random = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "dic_freq = {'wiki':{},'gigaword':{}, 'bnc':{}}\n",
    "\n",
    "#bnc\n",
    "with zipfile.ZipFile(WDIR + \"bnc_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['bnc']:\n",
    "        dic_freq['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['bnc']:\n",
    "        dic_svodesh['bnc'][w] = model.most_similar(w,topn=num)\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['bnc']:\n",
    "        dic_random['bnc'][w] = model.most_similar(w,topn=num)\n",
    "#gigaword\n",
    "with zipfile.ZipFile(WDIR + \"gigaword_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['gigaword']:\n",
    "        try:\n",
    "            dic_freq['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['gigaword'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['gigaword']:\n",
    "        try:\n",
    "            dic_svodesh['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['gigaword'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['gigaword']:\n",
    "        try:\n",
    "            dic_random['gigaword'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            print(w)\n",
    "            dic_random['gigaword'][w] = []        \n",
    "#wiki\n",
    "with zipfile.ZipFile(WDIR + \"wiki_en.zip\", \"r\") as archive:\n",
    "    stream = archive.open(\"model.txt\")\n",
    "model = open_model(stream)\n",
    "for w in list(fr['word']):\n",
    "    if w not in dic_freq['wiki']:\n",
    "        try:\n",
    "            dic_freq['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_freq['wiki'][w] = []\n",
    "for w in list(sv['word']):\n",
    "    if w not in dic_svodesh['wiki']:\n",
    "        try:\n",
    "            dic_svodesh['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_svodesh['wiki'][w] = []\n",
    "for w in list(rn['word']):\n",
    "    if w not in dic_random['wiki']:\n",
    "        try:\n",
    "            dic_random['wiki'][w] = model.most_similar(w,topn=num)\n",
    "        except:\n",
    "            dic_random['wiki'][w] = []       \n",
    "        \n",
    "rows_list = []\n",
    "for word in list(sv['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'svodesh'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_svodesh['wiki'][word]),get_words(dic_svodesh['bnc'][word]),get_words(dic_svodesh['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(rn['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'random'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_random['wiki'][word]),get_words(dic_random['bnc'][word]),get_words(dic_random['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "for word in list(fr['word']):\n",
    "        dict1 = {}\n",
    "        dict1['word'] = word\n",
    "        dict1['svodesh/random'] = 'freq'\n",
    "        dict1['% intersection'] = count_set(get_words(dic_freq['wiki'][word]),get_words(dic_freq['bnc'][word]),get_words(dic_freq['gigaword'][word]))\n",
    "        rows_list.append(dict1)\n",
    "df300 = pd.DataFrame(rows_list) \n",
    "df300.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#frequent\n",
    "fr  = df300[df300['svodesh/random']=='freq']\n",
    "#svodesh\n",
    "sv = df300[df300['svodesh/random']=='svodesh']\n",
    "#random\n",
    "rn = df300[df300['svodesh/random']=='random']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=18542.5, pvalue=0.9999999999981606)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=14851.0, pvalue=0.9934140397298331)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(sv['% intersection']), sorted(fr['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MannwhitneyuResult(statistic=17688.5, pvalue=0.9999999983371942)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mannwhitneyu(sorted(fr['% intersection']), sorted(rn['% intersection']), use_continuity=True, alternative='less')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df300.to_csv(path_or_buf='/media/mi_air/0F0B7DDE62EEA81E/vector/closest_word_intersection_300_eng.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
